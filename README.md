# ðŸ©º Kvasir-HealthAI: Advanced U-Net Pipeline for Gastrointestinal Polyp Segmentation

![Kvasir-HealthAI Banner](sample/banner.png)

---

## ðŸ“˜ Overview
**Kvasir-HealthAI** is an end-to-end deep learning pipeline for **gastrointestinal polyp segmentation** using the [Kvasir-SEG dataset](https://datasets.simula.no/kvasir-seg/).  
It features a modular design with preprocessing, training, and explainability stages â€” enabling reproducible, high-performance medical segmentation.

---

## âš™ï¸ Preprocessing Pipeline
**On-the-fly image enhancement** improves illumination uniformity and texture contrast.  
Each input frame passes through:

| Stage | Technique | Purpose |
|--------|------------|----------|
| 1ï¸âƒ£ | Specular highlight removal | Reduces glare reflections |
| 2ï¸âƒ£ | Homomorphic filtering | Corrects uneven illumination |
| 3ï¸âƒ£ | Guided filtering | Smooths noise while preserving edges |
| 4ï¸âƒ£ | CLAHE | Local contrast enhancement |
| 5ï¸âƒ£ | Retoning | Normalizes brightness and tone range |

### Example
| Original | After Preprocessing |
|-----------|--------------------|
| ![](sample/preprocess_before.png) | ![](sample/preprocess_after.png) |

**Effect on training**
- Higher Dice & IoU  
- Fewer false negatives in low-contrast areas  
- Faster convergence and more stable learning  

---

## ðŸ§  Training Setup
```bash
python -m src.training.train
```
**Default Hyperparameters**

| Parameter | Value |
|------------|--------|
| Image Size | 256Ã—256 |
| Batch Size | 8 |
| Epochs | 40 |
| Learning Rate | 1e-3 (Adam) |
| Loss Function | BCE + Dice |
| Scheduler | Cosine Annealing + Early Stopping |
| Device | CUDA / CPU auto-detect |

**Best Result**

**Performance Summary**

> ðŸŽ¯ **Dice:** `0.8554`â€ƒâ€ƒðŸ“ˆ **IoU:** `0.7838`â€ƒâ€ƒâš™ï¸ **Learning Rate:** `3.75e-05`

---

## ðŸ“Š Results

| Metric | Value |
|---------|--------|
| **Dice** | 0.8554 |
| **IoU** | 0.7838 |
| **Validation Loss** | 0.1603 |
| **Train Loss** | 0.0416 |

### Training Curves

| Loss Curves | Metrics (Dice / IoU) |
|--------------|----------------------|
| ![](sample/loss_curves.png) | ![](sample/metrics_curves.png) |

---

## ðŸ” Explainability (XAI)

**SegGrad-CAM** is used to visualize the modelâ€™s focus regions during segmentation.  
It highlights the areas contributing most to the final prediction, enabling interpretability and reliability in medical AI systems.

### Visualization Example

| Input | Grad-CAM | Overlay |
|--------|-----------|----------|
| ![](sample/xai_input.png) | ![](sample/xai_gradcam.png) | ![](sample/overlay.png) |

---

## ðŸ§° Folder Structure

Kvasir-HealthAI/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset/                  # Dataset loading & augmentation
â”‚   â”œâ”€â”€ models/                   # U-Net model definitions
â”‚   â”œâ”€â”€ preprocessing/            # Image preprocessing pipeline
â”‚   â”œâ”€â”€ training/                 # Loss, training loop, early stopping
â”‚   â”œâ”€â”€ explainability/           # Grad-CAM integration
â”‚   â”œâ”€â”€ utils/                    # Visualization & metrics
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                   # Raw sample visuals
â”‚   â”œâ”€â”€ results/                  # Training logs, plots, checkpoints
â”‚   â”œâ”€â”€ xai_visualizations/       # Grad-CAM outputs
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ inference_example.py
â”‚   â”œâ”€â”€ explainability_demo.py
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ LICENSE


---

## ðŸ§ª Quick Inference

```python
from src.models.unet import UNet
from src.utils.visualization import overlay_mask
import torch, cv2

model = UNet(in_ch=3, out_ch=1, base=64)
model.load_state_dict(torch.load("assets/results/unet/best_unet.pt"))
model.eval()

img = cv2.imread("assets/images/test_sample.png")
x = torch.from_numpy(img.transpose(2,0,1)).unsqueeze(0).float()/255.
with torch.no_grad():
    mask = torch.sigmoid(model(x))[0,0].numpy()

```

## ðŸ§­ Roadmap

- [ ] Add **Attention U-Net** and **U-Net++** variants  
- [ ] Deploy inference as **FastAPI + ONNX Runtime**  
- [ ] Integrate **Weights & Biases (wandb)** for experiment tracking  
- [ ] Enable **mixed precision** for Jetson / Edge AI deployment  
- [ ] Expand preprocessing for multi-center datasets  
- [ ] Publish pretrained models on **Hugging Face Hub**  

---

## ðŸ§‘â€ðŸ’» Author

**Ahmet Yasir Duman**  
Computer Engineer â€” *Healthcare AI & Computer Vision*  
ðŸ“§ [ahmetyasirduman@gmail.com](mailto:ahmetyasirduman@gmail.com)  
ðŸ”— [LinkedIn](https://www.linkedin.com/in/ahmetyasirduman) â€¢ [GitHub](https://github.com/ahmetduman23)

---
https://github.com/ahmetduman23/Kvasir-HealthAI

## ðŸ©¶ Citation

If you use this repository, please cite it as:

```bibtex
@misc{duman2025kvasirhealthai,
  author       = {Ahmet Yasir Duman},
  title        = {Kvasir-HealthAI: Advanced U-Net Pipeline for Gastrointestinal Polyp Segmentation},
  year         = {2025},
  url          = {https://github.com/ahmetduman23/Kvasir-HealthAI}
}

## ðŸ“œ License

This project is licensed under the **MIT License**.  
You are free to use, modify, and distribute the code with proper attribution.  
See the [LICENSE](LICENSE) file for complete details.

---

> **Kvasir-HealthAI** â€” bridging *Medical Imaging* and *Explainable Deep Learning.*

Â© 2025 Ahmet Yasir Duman â€” All rights reserved.
